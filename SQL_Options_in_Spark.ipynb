{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Options in Spark\n",
    "\n",
    "PySpark provides two main options when it comes to using staight SQL. Spark SQL and SQL Transformer. \n",
    "\n",
    "## 1. Spark SQL\n",
    "\n",
    "Spark TempView provides two functions that allow users to run **SQL** queries against a Spark DataFrame: \n",
    "\n",
    " - **createOrReplaceTempView:** The lifetime of this temporary view is tied to the SparkSession that was used to create the dataset. It creates (or replaces if that view name already exists) a lazily evaluated \"view\" that you can then use like a hive table in Spark SQL. It does not persist to memory unless you cache the dataset that underpins the view.\n",
    " - **createGlobalTempView:** The lifetime of this temporary view is tied to this Spark application. This feature is useful when you want to share data among different sessions and keep alive until your application ends.\n",
    "\n",
    "A **Spark Session vs. Spark application:**\n",
    "\n",
    "**Spark application** can be used:\n",
    "\n",
    "- for a single batch job\n",
    "- an interactive session with multiple jobs\n",
    "- a long-lived server continually satisfying requests\n",
    "- A Spark job can consist of more than just a single map and reduce.\n",
    "- can consist of more than one Spark Session. \n",
    "\n",
    "A **SparkSession** on the other hand:\n",
    "\n",
    " - is an interaction between two or more entities. \n",
    " - can be created without creating SparkConf, SparkContext or SQLContext, (theyâ€™re encapsulated within the SparkSession which is new to Spark 2.0)\n",
    "\n",
    "\n",
    "## 2. SQL Transformer\n",
    "\n",
    "You also have the option to use the SQL transformer option where you can write free-form SQL scripts as well.\n",
    "\n",
    "# SQL Options within regular PySpark calls\n",
    "\n",
    "1. The expr function in PySparks SQL Function Library\n",
    "2. PySparks selectExpr function\n",
    "\n",
    "We will go over all these in detail so buckel up!\n",
    "\n",
    "\n",
    "Let's start with Spark SQL. But first we need to create a Spark Session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://orcuns-mbp-2:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkSQL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7f45a998d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Read in our DataFrame for this Notebook\n",
    "\n",
    "### About this data\n",
    "\n",
    "Recorded crime for the Police Force Areas of England and Wales. The data are rolling 12-month totals, with points at the end of each financial year between year ending March 2003 to March 2007 and at the end of each quarter from June 2007.\n",
    "\n",
    "**Source:** https://www.kaggle.com/r3w0p4/recorded-crime-data-at-police-force-area-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by reading a basic csv dataset\n",
    "# Let Spark know about the header and infer the Schema types!\n",
    "\n",
    "path = 'Datasets/'\n",
    "\n",
    "crime = spark.read.csv(path+\"rec-crime-pfa.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12 months ending</th>\n",
       "      <th>PFA</th>\n",
       "      <th>Region</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Rolling year total number of offences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>All other theft offences</td>\n",
       "      <td>25959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Bicycle theft</td>\n",
       "      <td>3090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Criminal damage and arson</td>\n",
       "      <td>26202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Death or serious injury caused by illegal driving</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Domestic burglary</td>\n",
       "      <td>14561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  12 months ending                PFA      Region  \\\n",
       "0       31/03/2003  Avon and Somerset  South West   \n",
       "1       31/03/2003  Avon and Somerset  South West   \n",
       "2       31/03/2003  Avon and Somerset  South West   \n",
       "3       31/03/2003  Avon and Somerset  South West   \n",
       "4       31/03/2003  Avon and Somerset  South West   \n",
       "\n",
       "                                             Offence  \\\n",
       "0                           All other theft offences   \n",
       "1                                      Bicycle theft   \n",
       "2                          Criminal damage and arson   \n",
       "3  Death or serious injury caused by illegal driving   \n",
       "4                                  Domestic burglary   \n",
       "\n",
       "   Rolling year total number of offences  \n",
       "0                                  25959  \n",
       "1                                   3090  \n",
       "2                                  26202  \n",
       "3                                      2  \n",
       "4                                  14561  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is way better\n",
    "crime.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 12 months ending: string (nullable = true)\n",
      " |-- PFA: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Offence: string (nullable = true)\n",
      " |-- Rolling year total number of offences: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(crime.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in order for us to perform SQL calls off of this dataframe, we will need to rename any variables that have spaces in them. We will not be using the first variable so I'll leave that one as is, but we will be using the last variable, so I will go ahead and change that to Count so we can work with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 12 months ending: string (nullable = true)\n",
      " |-- PFA: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Offence: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = crime.withColumnRenamed('Rolling year total number of offences','Count') #.withColumn(\"12 months ending\", crime[\"12 months ending\"].cast(DateType())).\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view of the dataframe\n",
    "df.createOrReplaceTempView(\"tempview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|\n",
      "|      31/03/2003|     Bedfordshire|      East|All other theft o...| 8797|\n",
      "|      31/03/2003|     Bedfordshire|      East|Criminal damage a...|10006|\n",
      "|      31/03/2003|     Bedfordshire|      East|   Domestic burglary| 3784|\n",
      "|      31/03/2003|     Bedfordshire|      East|       Drug offences| 1069|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Then Query the temp view\n",
    "spark.sql(\"SELECT * FROM tempview WHERE Count > 1000\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>PFA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South West</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South West</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South West</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South West</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South West</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Region                PFA\n",
       "0  South West  Avon and Somerset\n",
       "1  South West  Avon and Somerset\n",
       "2  South West  Avon and Somerset\n",
       "3  South West  Avon and Somerset\n",
       "4  South West  Avon and Somerset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or choose which vars you want\n",
    "spark.sql(\"SELECT Region, PFA FROM tempview WHERE Count > 1000\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12 months ending</th>\n",
       "      <th>PFA</th>\n",
       "      <th>Region</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>All other theft offences</td>\n",
       "      <td>25959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Bicycle theft</td>\n",
       "      <td>3090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Criminal damage and arson</td>\n",
       "      <td>26202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Domestic burglary</td>\n",
       "      <td>14561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Drug offences</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  12 months ending                PFA      Region                    Offence  \\\n",
       "0       31/03/2003  Avon and Somerset  South West   All other theft offences   \n",
       "1       31/03/2003  Avon and Somerset  South West              Bicycle theft   \n",
       "2       31/03/2003  Avon and Somerset  South West  Criminal damage and arson   \n",
       "3       31/03/2003  Avon and Somerset  South West          Domestic burglary   \n",
       "4       31/03/2003  Avon and Somerset  South West              Drug offences   \n",
       "\n",
       "   Count  \n",
       "0  25959  \n",
       "1   3090  \n",
       "2  26202  \n",
       "3  14561  \n",
       "4   2308  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also pass your query results to an object \n",
    "# (we don't need to use .collect() here)\n",
    "sql_results = spark.sql(\"SELECT * FROM tempview WHERE Count > 1000 AND Region='South West'\")\n",
    "sql_results.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fraud: CIFAS</td>\n",
       "      <td>7678981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North West</td>\n",
       "      <td>30235732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>3029117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wales</td>\n",
       "      <td>11137260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>42691902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Region     Total\n",
       "0              Fraud: CIFAS   7678981\n",
       "1                North West  30235732\n",
       "2  British Transport Police   3029117\n",
       "3                     Wales  11137260\n",
       "4                    London  42691902"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can even do aggregated \"group by\" calls like this\n",
    "spark.sql(\"SELECT Region, sum(Count) AS Total FROM tempview GROUP BY Region\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basically anything goes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Transformer\n",
    "\n",
    "You also have the option to use the SQL transformer option where you can write freeform SQL scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to import SQL transformer\n",
    "from pyspark.ml.feature import SQLTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Then we create an SQL call \n",
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT PFA,Region,Offence FROM __THIS__\") \n",
    "# And use it to transform our df object\n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.feature.SQLTransformer"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sqlTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: __THAT__; line 1 pos 31'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o198.transform.\n: org.apache.spark.sql.AnalysisException: Table or view not found: __THAT__; line 1 pos 31\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:47)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:731)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:683)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:713)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:706)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:329)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:706)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:652)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:106)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)\n\tat org.apache.spark.ml.feature.SQLTransformer.transformSchema(SQLTransformer.scala:86)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.feature.SQLTransformer.transform(SQLTransformer.scala:68)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:844)\nCaused by: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: Table or view '__that__' not found in database 'default';\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalog$class.requireTableExists(ExternalCatalog.scala:48)\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.requireTableExists(InMemoryCatalog.scala:45)\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.getTable(InMemoryCatalog.scala:326)\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.getTable(ExternalCatalogWithListener.scala:138)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.lookupRelation(SessionCatalog.scala:706)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:728)\n\t... 56 more\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-41e00be31d8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     statement=\"SELECT PFA,Region,Offence FROM __THAT__\") \n\u001b[1;32m      4\u001b[0m \u001b[0;31m# And use it to transform our df object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msqlTrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Table or view not found: __THAT__; line 1 pos 31'"
     ]
    }
   ],
   "source": [
    "# Note that \"__THIS__\" is a special word and cannot be change to __THAT__ for example\n",
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT PFA,Region,Offence FROM __THAT__\") \n",
    "# And use it to transform our df object\n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SQLTransformer' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1ccfb6779f31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSQLTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SELECT PFA,Region,Offence FROM __THIS__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SQLTransformer' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "# Also Note that a call like this won't work...\n",
    "SQLTransformer(statement=\"SELECT PFA,Region,Offence FROM __THIS__\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now how about a group by call**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             Offence|   Total|\n",
      "+--------------------+--------+\n",
      "|Public order offe...|10925676|\n",
      "|       Bicycle theft| 5297006|\n",
      "|Residential burglary| 1671469|\n",
      "|Violence without ...|16590158|\n",
      "|All other theft o...|30979393|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Note that this call will not work on the original dataframe \"crime\" when the variable \"Count\" is a string\n",
    "\n",
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT Offence, SUM(Count) as Total FROM __THIS__ GROUP BY Offence\") \n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And a where statement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|              PFA|             Offence|\n",
      "+-----------------+--------------------+\n",
      "|Avon and Somerset|All other theft o...|\n",
      "|Avon and Somerset|       Bicycle theft|\n",
      "|Avon and Somerset|Criminal damage a...|\n",
      "|Avon and Somerset|   Domestic burglary|\n",
      "|Avon and Somerset|       Drug offences|\n",
      "+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT PFA,Offence FROM __THIS__ WHERE Count > 1000\") \n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can also, of course, read the output into a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|              PFA|             Offence|\n",
      "+-----------------+--------------------+\n",
      "|Avon and Somerset|All other theft o...|\n",
      "|Avon and Somerset|       Bicycle theft|\n",
      "|Avon and Somerset|Criminal damage a...|\n",
      "|Avon and Somerset|   Domestic burglary|\n",
      "|Avon and Somerset|       Drug offences|\n",
      "+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = sqlTrans.transform(df)\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Options within regular PySpark calls\n",
    "\n",
    "### The expr function in PySparks SQL Function Library\n",
    "\n",
    "You can also use the expr function within the pyspark.sql.functions library coupled with either PySpark's withColumn function or the select function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to read in the library\n",
    "from pyspark.sql.functions import expr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a percent column to the dataframe. To do this, first we need to get the total number of rows in the dataframe (we can't soft this unfortunatly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|    Total|\n",
      "+---------+\n",
      "|244720928|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT SUM(Count) as Total FROM __THIS__\") \n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|percent|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Death or serious ...|    2|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|            Homicide|   19|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Possession of wea...|  735|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Stalking and hara...|  740|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|   0.02|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|    0.0|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We could add a percent column to our df \n",
    "# that shows the offence %\n",
    "# with the \"withColumn\" command\n",
    "df.withColumn(\"percent\",expr(\"round((count/244720928)*100,2)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|percent|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Death or serious ...|    2|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|            Homicide|   19|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Possession of wea...|  735|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Stalking and hara...|  740|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|   0.02|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|    0.0|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Same thing with the \"select\" command\n",
    "df.select(\"*\",expr(\"round((count/244720928)*100,2) AS percent\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySparks selectExpr function\n",
    "\n",
    "Very similar idea here but slightly different syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|percent|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Death or serious ...|    2|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|            Homicide|   19|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Possession of wea...|  735|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Stalking and hara...|  740|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|   0.02|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|    0.0|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"*\",\"round((count/244720928)*100,2) AS percent\").filter(\"Region ='South West'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's all folks! Great job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|\n",
      "|      31/03/2003|     Bedfordshire|      East|All other theft o...| 8797|\n",
      "|      31/03/2003|     Bedfordshire|      East|Criminal damage a...|10006|\n",
      "|      31/03/2003|     Bedfordshire|      East|   Domestic burglary| 3784|\n",
      "|      31/03/2003|     Bedfordshire|      East|       Drug offences| 1069|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM tempview WHERE Count > 1000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we create an SQL call \n",
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT * FROM __THIS__ WHERE Count > 1000\")\n",
    "# And use it to transform our df object\n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|\n",
      "|      31/03/2003|     Bedfordshire|      East|All other theft o...| 8797|\n",
      "|      31/03/2003|     Bedfordshire|      East|Criminal damage a...|10006|\n",
      "|      31/03/2003|     Bedfordshire|      East|   Domestic burglary| 3784|\n",
      "|      31/03/2003|     Bedfordshire|      East|       Drug offences| 1069|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Then we create an SQL call \n",
    "SQLTransformer(statement=\"SELECT * FROM __THIS__ WHERE Count > 1000\").transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Options in Spark HW Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with Spark SQL. But first we need to create a Spark Session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.180:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkSQLHWSolutions</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ef8a3a2148>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"SparkSQLHWSolutions\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in our DataFrame for this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook we will be using the Google Play Store csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains a list of Google Play Store Apps and info about the apps like the category, rating, reviews, size, etc.\n",
    "\n",
    "Source: https://www.kaggle.com/lava18/google-play-store-apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Datasets/'\n",
    "\n",
    "googlep = spark.read.csv(path+\"googleplaystore.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Current Ver</th>\n",
       "      <th>Android Ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>159</td>\n",
       "      <td>19M</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>January 7, 2018</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Coloring book moana</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>967</td>\n",
       "      <td>14M</td>\n",
       "      <td>500,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design;Pretend Play</td>\n",
       "      <td>January 15, 2018</td>\n",
       "      <td>2.0.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>U Launcher Lite â€“ FREE Live Cool Themes, Hide ...</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87510</td>\n",
       "      <td>8.7M</td>\n",
       "      <td>5,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>August 1, 2018</td>\n",
       "      <td>1.2.4</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sketch - Draw &amp; Paint</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>215644</td>\n",
       "      <td>25M</td>\n",
       "      <td>50,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Teen</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>June 8, 2018</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>4.2 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Pixel Draw - Number Art Coloring Book</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>967</td>\n",
       "      <td>2.8M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design;Creativity</td>\n",
       "      <td>June 20, 2018</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.4 and up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 App        Category Rating  \\\n",
       "0     Photo Editor & Candy Camera & Grid & ScrapBook  ART_AND_DESIGN    4.1   \n",
       "1                                Coloring book moana  ART_AND_DESIGN    3.9   \n",
       "2  U Launcher Lite â€“ FREE Live Cool Themes, Hide ...  ART_AND_DESIGN    4.7   \n",
       "3                              Sketch - Draw & Paint  ART_AND_DESIGN    4.5   \n",
       "4              Pixel Draw - Number Art Coloring Book  ART_AND_DESIGN    4.3   \n",
       "\n",
       "  Reviews  Size     Installs  Type Price Content Rating  \\\n",
       "0     159   19M      10,000+  Free     0       Everyone   \n",
       "1     967   14M     500,000+  Free     0       Everyone   \n",
       "2   87510  8.7M   5,000,000+  Free     0       Everyone   \n",
       "3  215644   25M  50,000,000+  Free     0           Teen   \n",
       "4     967  2.8M     100,000+  Free     0       Everyone   \n",
       "\n",
       "                      Genres      Last Updated         Current Ver  \\\n",
       "0               Art & Design   January 7, 2018               1.0.0   \n",
       "1  Art & Design;Pretend Play  January 15, 2018               2.0.0   \n",
       "2               Art & Design    August 1, 2018               1.2.4   \n",
       "3               Art & Design      June 8, 2018  Varies with device   \n",
       "4    Art & Design;Creativity     June 20, 2018                 1.1   \n",
       "\n",
       "    Android Ver  \n",
       "0  4.0.3 and up  \n",
       "1  4.0.3 and up  \n",
       "2  4.0.3 and up  \n",
       "3    4.2 and up  \n",
       "4    4.4 and up  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googlep.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- App: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      " |-- Reviews: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- Installs: string (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Price: string (nullable = true)\n",
      " |-- Content Rating: string (nullable = true)\n",
      " |-- Genres: string (nullable = true)\n",
      " |-- Last Updated: string (nullable = true)\n",
      " |-- Current Ver: string (nullable = true)\n",
      " |-- Android Ver: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "googlep.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we need to edit some of the datatypes. Let's just update Rating, Reviews and Price as integer (float for Rating) values for now, since the Size and Installs variables will need a bit more cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- App: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Rating: float (nullable = true)\n",
      " |-- Reviews: integer (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- Installs: string (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      " |-- Content Rating: string (nullable = true)\n",
      " |-- Genres: string (nullable = true)\n",
      " |-- Last Updated: string (nullable = true)\n",
      " |-- Current Ver: string (nullable = true)\n",
      " |-- Android Ver: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Current Ver</th>\n",
       "      <th>Android Ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>159</td>\n",
       "      <td>19M</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>January 7, 2018</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Coloring book moana</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>967</td>\n",
       "      <td>14M</td>\n",
       "      <td>500,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design;Pretend Play</td>\n",
       "      <td>January 15, 2018</td>\n",
       "      <td>2.0.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>U Launcher Lite â€“ FREE Live Cool Themes, Hide ...</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87510</td>\n",
       "      <td>8.7M</td>\n",
       "      <td>5,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>August 1, 2018</td>\n",
       "      <td>1.2.4</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sketch - Draw &amp; Paint</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>215644</td>\n",
       "      <td>25M</td>\n",
       "      <td>50,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Teen</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>June 8, 2018</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>4.2 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Pixel Draw - Number Art Coloring Book</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>967</td>\n",
       "      <td>2.8M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design;Creativity</td>\n",
       "      <td>June 20, 2018</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.4 and up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 App        Category  Rating  \\\n",
       "0     Photo Editor & Candy Camera & Grid & ScrapBook  ART_AND_DESIGN     4.1   \n",
       "1                                Coloring book moana  ART_AND_DESIGN     3.9   \n",
       "2  U Launcher Lite â€“ FREE Live Cool Themes, Hide ...  ART_AND_DESIGN     4.7   \n",
       "3                              Sketch - Draw & Paint  ART_AND_DESIGN     4.5   \n",
       "4              Pixel Draw - Number Art Coloring Book  ART_AND_DESIGN     4.3   \n",
       "\n",
       "   Reviews  Size     Installs  Type  Price Content Rating  \\\n",
       "0      159   19M      10,000+  Free      0       Everyone   \n",
       "1      967   14M     500,000+  Free      0       Everyone   \n",
       "2    87510  8.7M   5,000,000+  Free      0       Everyone   \n",
       "3   215644   25M  50,000,000+  Free      0           Teen   \n",
       "4      967  2.8M     100,000+  Free      0       Everyone   \n",
       "\n",
       "                      Genres      Last Updated         Current Ver  \\\n",
       "0               Art & Design   January 7, 2018               1.0.0   \n",
       "1  Art & Design;Pretend Play  January 15, 2018               2.0.0   \n",
       "2               Art & Design    August 1, 2018               1.2.4   \n",
       "3               Art & Design      June 8, 2018  Varies with device   \n",
       "4    Art & Design;Creativity     June 20, 2018                 1.1   \n",
       "\n",
       "    Android Ver  \n",
       "0  4.0.3 and up  \n",
       "1  4.0.3 and up  \n",
       "2  4.0.3 and up  \n",
       "3    4.2 and up  \n",
       "4    4.4 and up  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "df = googlep.withColumn(\"Rating\", googlep[\"Rating\"].cast(FloatType())) \\\n",
    "            .withColumn(\"Reviews\", googlep[\"Reviews\"].cast(IntegerType())) \\\n",
    "            .withColumn(\"Price\", googlep[\"Price\"].cast(IntegerType()))\n",
    "print(df.printSchema())\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create TempviewÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and create a tempview of the dataframe so we can work with it in spark sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view of the dataframe\n",
    "df.createOrReplaceTempView(\"tempview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select all apps with ratings above 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Current Ver</th>\n",
       "      <th>Android Ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>U Launcher Lite â€“ FREE Live Cool Themes, Hide ...</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87510</td>\n",
       "      <td>8.7M</td>\n",
       "      <td>5,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>August 1, 2018</td>\n",
       "      <td>1.2.4</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sketch - Draw &amp; Paint</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>215644</td>\n",
       "      <td>25M</td>\n",
       "      <td>50,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Teen</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>June 8, 2018</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>4.2 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Pixel Draw - Number Art Coloring Book</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>967</td>\n",
       "      <td>2.8M</td>\n",
       "      <td>100,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design;Creativity</td>\n",
       "      <td>June 20, 2018</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.4 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Paper flowers instructions</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>167</td>\n",
       "      <td>5.6M</td>\n",
       "      <td>50,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>March 26, 2017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Garden Coloring Book</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>13791</td>\n",
       "      <td>33M</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>September 20, 2017</td>\n",
       "      <td>2.9.2</td>\n",
       "      <td>3.0 and up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 App        Category  Rating  \\\n",
       "0  U Launcher Lite â€“ FREE Live Cool Themes, Hide ...  ART_AND_DESIGN     4.7   \n",
       "1                              Sketch - Draw & Paint  ART_AND_DESIGN     4.5   \n",
       "2              Pixel Draw - Number Art Coloring Book  ART_AND_DESIGN     4.3   \n",
       "3                         Paper flowers instructions  ART_AND_DESIGN     4.4   \n",
       "4                               Garden Coloring Book  ART_AND_DESIGN     4.4   \n",
       "\n",
       "   Reviews  Size     Installs  Type  Price Content Rating  \\\n",
       "0    87510  8.7M   5,000,000+  Free      0       Everyone   \n",
       "1   215644   25M  50,000,000+  Free      0           Teen   \n",
       "2      967  2.8M     100,000+  Free      0       Everyone   \n",
       "3      167  5.6M      50,000+  Free      0       Everyone   \n",
       "4    13791   33M   1,000,000+  Free      0       Everyone   \n",
       "\n",
       "                    Genres        Last Updated         Current Ver  \\\n",
       "0             Art & Design      August 1, 2018               1.2.4   \n",
       "1             Art & Design        June 8, 2018  Varies with device   \n",
       "2  Art & Design;Creativity       June 20, 2018                 1.1   \n",
       "3             Art & Design      March 26, 2017                 1.0   \n",
       "4             Art & Design  September 20, 2017               2.9.2   \n",
       "\n",
       "    Android Ver  \n",
       "0  4.0.3 and up  \n",
       "1    4.2 and up  \n",
       "2    4.4 and up  \n",
       "3    2.3 and up  \n",
       "4    3.0 and up  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then Query the temp view\n",
    "spark.sql(\"SELECT * FROM tempview WHERE Rating > 4.1\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Now pass your results to an object (ie create a spark dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select just the App and Rating column where the Category is in the Comic category and the Rating is above 4.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Manga Master - Best manga &amp; comic reader</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GANMA! - All original stories free of charge f...</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RÃ¶hrich Werner Soundboard</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Unicorn Pokez - Color By Number</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Manga - read Thai translation</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 App  Rating\n",
       "0           Manga Master - Best manga & comic reader     4.6\n",
       "1  GANMA! - All original stories free of charge f...     4.7\n",
       "2                          RÃ¶hrich Werner Soundboard     4.7\n",
       "3                    Unicorn Pokez - Color By Number     4.8\n",
       "4                      Manga - read Thai translation     4.6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or pass it to an object\n",
    "sql_results = spark.sql(\"SELECT App,Rating FROM tempview WHERE Category = 'COMICS' AND Rating > 4.5\")\n",
    "sql_results.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Which category has the most cumulative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only select the one category with the most reivews.\n",
    "\n",
    "Note: will require adding all the review together for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Total_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GAME</td>\n",
       "      <td>1585422349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category  Total_Reviews\n",
       "0     GAME     1585422349"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT Category, sum(Reviews) AS Total_Reviews FROM tempview GROUP BY Category ORDER BY Total_Reviews DESC\") \\\n",
    "        .limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Which App has the most reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display ONLY the top result\n",
    "\n",
    "Include only the App column and the Reviews column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|     App| Reviews|\n",
      "+--------+--------+\n",
      "|Facebook|78158306|\n",
      "+--------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT App, Reviews FROM tempview ORDER BY Reviews DESC\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Select all apps that contain the word 'dating' anywhere in the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Current Ver</th>\n",
       "      <th>Android Ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Meet, chat &amp; date. Free dating app - Chocolate...</td>\n",
       "      <td>DATING</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8661</td>\n",
       "      <td>9.5M</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Mature 17+</td>\n",
       "      <td>Dating</td>\n",
       "      <td>April 3, 2018</td>\n",
       "      <td>0.1.11</td>\n",
       "      <td>4.0 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Friend Find: free chat + flirt dating app</td>\n",
       "      <td>DATING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>11M</td>\n",
       "      <td>100+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Mature 17+</td>\n",
       "      <td>Dating</td>\n",
       "      <td>July 31, 2018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.4 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Spine- The dating app</td>\n",
       "      <td>DATING</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9.3M</td>\n",
       "      <td>500+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Teen</td>\n",
       "      <td>Dating</td>\n",
       "      <td>July 14, 2018</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Princess Closet : Otome games free dating sim</td>\n",
       "      <td>FAMILY</td>\n",
       "      <td>4.5</td>\n",
       "      <td>29495</td>\n",
       "      <td>56M</td>\n",
       "      <td>1,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Teen</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>1.11.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>happn â€“ Local dating app</td>\n",
       "      <td>LIFESTYLE</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1118201</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>10,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Mature 17+</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>July 24, 2018</td>\n",
       "      <td>Varies with device</td>\n",
       "      <td>Varies with device</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 App   Category  Rating  \\\n",
       "0  Meet, chat & date. Free dating app - Chocolate...     DATING     3.9   \n",
       "1          Friend Find: free chat + flirt dating app     DATING     NaN   \n",
       "2                              Spine- The dating app     DATING     5.0   \n",
       "3      Princess Closet : Otome games free dating sim     FAMILY     4.5   \n",
       "4                           happn â€“ Local dating app  LIFESTYLE     4.3   \n",
       "\n",
       "   Reviews                Size     Installs  Type  Price Content Rating  \\\n",
       "0     8661                9.5M   1,000,000+  Free      0     Mature 17+   \n",
       "1       23                 11M         100+  Free      0     Mature 17+   \n",
       "2        5                9.3M         500+  Free      0           Teen   \n",
       "3    29495                 56M   1,000,000+  Free      0           Teen   \n",
       "4  1118201  Varies with device  10,000,000+  Free      0     Mature 17+   \n",
       "\n",
       "       Genres   Last Updated         Current Ver         Android Ver  \n",
       "0      Dating  April 3, 2018              0.1.11          4.0 and up  \n",
       "1      Dating  July 31, 2018                 1.0          4.4 and up  \n",
       "2      Dating  July 14, 2018                 4.0        4.0.3 and up  \n",
       "3  Simulation   May 24, 2018              1.11.0        4.0.3 and up  \n",
       "4   Lifestyle  July 24, 2018  Varies with device  Varies with device  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM tempview WHERE App LIKE '%dating%'\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use SQL Transformer to display how many free apps there are in this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to import SQL transformer\n",
    "from pyspark.ml.feature import SQLTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   10037|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT count(*) FROM __THIS__ WHERE Type = 'Free'\") \n",
    "sqlTrans.transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What is the most popular Genre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Genres|Total|\n",
      "+------+-----+\n",
      "| Tools|  842|\n",
      "+------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT Genres, count(*) as Total FROM __THIS__ GROUP BY Genres ORDER BY Total DESC\") \n",
    "sqlTrans.transform(df).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Select all the apps in the 'Tools' genre that have more than 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                 App| Reviews|\n",
      "+--------------------+--------+\n",
      "|   Moto File Manager|   38655|\n",
      "|              Google| 8033493|\n",
      "|    Google Translate| 5745093|\n",
      "|        Moto Display|   18239|\n",
      "|      Motorola Alert|   24199|\n",
      "|     Motorola Assist|   37333|\n",
      "|Cache Cleaner-DU ...|12759663|\n",
      "|  Moto Suggestions â„¢|     308|\n",
      "|          Moto Voice|   33216|\n",
      "|          Calculator|   40770|\n",
      "+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT App, Reviews FROM __THIS__ WHERE Genres = 'Tools' AND Reviews > 100\") \n",
    "sqlTrans.transform(df).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
